# 集合（容器）

![image-20200618162803323](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200618162803323.png)

Collection

List

![image-20200601160347458](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200601160347458.png)

一、先说下这个list

有三个 

Arraylist 内部是通过数组实现的 因为自带索引 所以允许元素进行快速随机访问，不过是有缺点的，每个元素之间不能有间隔，如果进行增加和删除的时候，需要先将数组进行复制和移动，代价很高，因此，只适合插入和删除。

## Collection

### List

**Arraylist**

内部是通过**数组**实现的，它运行对元素进行快速随机访问。缺点是增加或者删除元素时代价较高，因为需要对数组先进行复制然后移动。

**vector** 

与arraylist一样，是通过数组实现的 ，多了数组支持线程的同步 ，不过以为同步用verctor一般都不用它，因为需要很高的花费 一般情况用的是同步锁 copyonwriteArraylist来同步

**Linklist**

是用**链表**结构存储数据的，适合动态插入和删除 没有索引 所以随机访问和遍历速度是比较慢的 

可操作表头和表尾元素 ，当做队列和双向队列进行使用

### Set

Set方法：Set与list的区别就是里面的元素是无序的，但是值不能重复，是根据每个hashcode进行判断



**HashSet**  存入的值是一个hash值 是没有顺序排序的 保证存入的唯一性 存入hash值 会使用equal 然后分不在每个hash桶里面 如果发生一个hash冲突的话 会进行头插法的形式来存放在每个hash桶里面的链表里。如果超过8的话 会进行一个红黑树的一个排序

具体如果涉及到hash扩容 需要再次复习查看下

**SortedSet** 基于红黑树实现，支持有序性操作，每增加一个对象都会进行排序 ，将对象插入的二叉树指定的位置

**LinkHashSet**（HashSet+LinkedHashMap）具有hashset的查找效率



## Map

**HashMap**（ConcurrentHashmap支持并发）

根据hashcode的值进行存储，可以直接定位到它的值，因而具有很快的访问速度，但是遍历顺序是不确定的，HashMap的线程是不安全的 底层是数组+链表+红黑树

**HashTbale** 

是遗留类 不建议使用 效率十分低下

**TreeMap** 

红黑树实现，可排序，需要对一个有序的key集合进行遍历时建议使用。 用的也比较少

**LinkeHashMap** 

是hashmap的一个子类 增加了一条双向链表 从而可以保存记录的插入顺序 。在用 Iterator 遍历 LinkedHashMap 时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。



## 下面是源码分析

扩容：ArrayList其实就是对旧数组进行位移得到新数组，再把新数组复制到新数组上，

增加删除都是复制需要指定元素后面的元素 然后增加就向右移 删除就是向左移

说下Arraylist的**CopyOnWriteArraylist**

其实就是读写锁，ReentrantLock获取对象锁的方式来实现线程安全。  

写的操作需要加锁，防止并发写入导致数据丢失，不直接操作原数组，先copy一个数组进行操作，写完后setArray方法把新的复制数组赋值给旧数组。

 CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。 

缺点就是内存占用大，数据不一致，写和读属于异步 所以不适用哪些实时性要求很高的场景



**现在说说ArrayList和LinkedList的区别，**

ArrayList是基于动态数组进行实现的，Linekdlist是基于双向链表的实现，基本差别和上面说的差不多

都不难 hash会比较难一点，源码主要说hash



HashMap

有一个非常重要的字段就是Node[]table 哈希桶数组，哈系桶默认是16，加载因子是0.75，超过12就进行扩容，一般扩容2倍，32个。本身就是一个映射，存放的位置是根据hashcode判断的，如果出现hash和key不相同的元素时（哈希冲突），就用链表和数组相结合的方式 （此方法就拉链法）。

说下 map.put的方法

会先判断是否为空，如果是就扩容

根据key来计算hashcode值，得到要插入的数组索引

然后判断key是否重复使用 如果是就覆盖

如果不是就开始遍历链表，头插法加移动的方式进行添加，还要判断链表元素是否大于8，如果大于8的话就用红黑树，最后判断整的hash是否需要扩容。

扩容会伴随着一次重新hash分配，并且会遍历hash表中所有的元素，是非常耗时的。在编写程序中，要尽量避免resize。 源码在下面，仔细阅读即可理解此方法。

HashMap的扩容

当Hashmap中的元素越来越多的时候，碰撞的几率也越来越高，所以为了提高查询的效率，就要对hashmap进行扩容，前面有说道，默认是16，然后加载因子是0.75，超过就会扩容一倍，这样其实是非常消耗性能的，所以我们已经预知hashmap中元素的个数，那么预设元素的个数能够有效提高性能。例如，我们有1000个元素，理论来说预设的值为1024 new HashMap（1024）就足够了，但是由于有0.75的加载因子，所以1024是不合适的，所以应该预设为2048才合适。



**JDK1.7：**

 ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 **ConcurrentHashMap 采用了分段锁（Segment**），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。  **Segment 继承自 ReentrantLock ，默认的并发级别为 16 。** 

简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承
ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每
个 Segment 是线程安全的，也就实现了全局的线程安全。

**JDK1.8：**

使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。  synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。 

## HashSet 

实现原理： HashSet底层由HashMap实现 ，值存放于HashMap的key上 ，HashMap的value统一为PRESENT 。

检查重复： 先对插入的元素的hashcode值和现有的元素的hashcode作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现，直接插入。但是如果发现有相同hashcode值的对象，这时会调用`equals（）`方法来检查hashcode相等的对象是否真的相同。  如果两者相同，HashSet就不会让加入操作成功 。

HashSet与HashMap的区别



##  LinkedHashMap 

 ### LinkedHashMap 实现LRU（least recently used）

- 设定最大缓存空间 MAX_ENTRIES 为 3；
- 使用 LinkedHashMap 的构造函数将 accessOrder 设置为 true，开启 LRU 顺序；
- 覆盖 removeEldestEntry() 方法实现，在节点多于 MAX_ENTRIES 就会将最近最久未使用的数据移除。

## BlockingQueue 的实现类

ArrayBlockingQueue 底层是数组，有界队列，如果我们要使用生产者-消费者模式，这是非常好的选择。

LinkedBlockingQueue 底层是链表，可以当做无界和有界队列来使用，所以大家不要以为它就是无界队列。

DelayQueue是一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部是延迟期满后保存时间最长的Delayed 元素。

SynchronousQueue 本身不带有空间来存储任何元素，使用上可以选择公平模式和非公平模式。

PriorityBlockingQueue 是无界队列，基于数组，数据结构为二叉堆，数组第一个也是树的根节点总是最小值。